import{_ as p,V as e,W as c,X as s,Y as n,Z as t,a0 as l,E as o}from"./framework-7208760f.js";const i={},m=s("h1",{id:"week2-深度学习常用组件",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#week2-深度学习常用组件","aria-hidden":"true"},"#"),n(" week2 深度学习常用组件")],-1),r=s("h2",{id:"梯度下降法",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#梯度下降法","aria-hidden":"true"},"#"),n(" 梯度下降法")],-1),u=s("ul",null,[s("li",null,[s("p",null,"根据梯度，更新权重")]),s("li",null,[s("p",null,"学习率控制权重更新的幅度")]),s("li",null,[s("p",null,[n("SGD："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"θ"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])]),s("mo",null,"="),s("msub",null,[s("mi",null,"θ"),s("mi",null,"t")]),s("mo",null,"−"),s("mi",null,"α"),s("mi",{mathvariant:"normal"},"∇"),s("mi",null,"L"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"θ"),s("mi",null,"t")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"\\theta_{t+1} = \\theta_{t} - \\alpha\\nabla L(\\theta_{t})")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.9028em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8444em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mord"},"∇"),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])])])])])],-1),d=s("h2",{id:"权重更新方式",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#权重更新方式","aria-hidden":"true"},"#"),n(" 权重更新方式")],-1),k=s("p",null,"Gradient descent: 所有样本一起计算梯度（累加）",-1),h=s("p",null,"Stochastic gradient descent: 每次使用一个样本计算梯度",-1),g=s("p",null,"Mini-batch gradient descent: 每次使用n个样本计算梯度（累加）",-1),y=s("h2",{id:"完整的反向传播过程",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#完整的反向传播过程","aria-hidden":"true"},"#"),n(" 完整的反向传播过程")],-1),v=s("ol",null,[s("li",null,[n("根据输入"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"x")]),s("annotation",{encoding:"application/x-tex"},"x")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"x")])])]),n("和模型当前权重，计算预测值"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"y"),s("msup",null,[s("mrow"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")])])]),s("annotation",{encoding:"application/x-tex"},"y^{'}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1369em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9425em"}},[s("span",{style:{top:"-2.9425em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.5795em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8278em"}},[s("span",{style:{top:"-2.931em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])])])])])])])])])])])])])]),s("li",null,[n("根据"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"y"),s("msup",null,[s("mrow"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")])])]),s("annotation",{encoding:"application/x-tex"},"y^{'}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1369em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9425em"}},[s("span",{style:{top:"-2.9425em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.5795em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8278em"}},[s("span",{style:{top:"-2.931em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])])])])])])])])])])])])]),n("和使用loss函数计算loss")]),s("li",null,"根据loss计算模型权重的梯度"),s("li",null,"使用梯度和学习率，根据优化器调整模型权重")],-1),b=l(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token triple-quoted-string string">&quot;&quot;&quot;
基于pytorch的网络编写
手动实现梯度计算和反向传播
加入激活函数
&quot;&quot;&quot;</span>

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> copy

<span class="token keyword">class</span> <span class="token class-name">TorchModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TorchModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>activation <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid
        self<span class="token punctuation">.</span>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>mse_loss <span class="token comment"># loss采用均方误差 </span>
    <span class="token comment"># 当输入真实标签，返回loss值：无真实标签，返回预测值</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        y_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        y_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span>
        <span class="token keyword">if</span> y <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> y_pred

<span class="token comment"># 自定义模型，接受一个参数矩阵作为入参</span>
<span class="token keyword">class</span> <span class="token class-name">DiyModel</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> weight<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> weight
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        y_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>diy_sigmoid<span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span>
        <span class="token keyword">if</span> y <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>diy_mse_loss<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> y_pred
    
    <span class="token comment"># sigmoid</span>
    <span class="token keyword">def</span> <span class="token function">diy_sigmoid</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 手动实现mse，均方差loss</span>
    <span class="token keyword">def</span> <span class="token function">diy_mse_loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> y_true<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y_true<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span>
    
    <span class="token comment"># 手动实现梯度计算</span>
    <span class="token keyword">def</span> <span class="token function">calculate_grad</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> y_true<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 前向过程</span>
        wx <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        sigmoid_wx <span class="token operator">=</span> self<span class="token punctuation">.</span>diy_sigmoid<span class="token punctuation">(</span>wx<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>diy_mse_loss<span class="token punctuation">(</span>sigmoid_wx<span class="token punctuation">,</span> y_true<span class="token punctuation">)</span>
        
        <span class="token comment"># 反向过程</span>
        grad_loss_sigmoid_wx <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y_true<span class="token punctuation">)</span>
        grad_sigmoid_wx_wx <span class="token operator">=</span> y_pred <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> y_pred<span class="token punctuation">)</span>
        grad_wx_w <span class="token operator">=</span> x
        
        <span class="token comment"># 链式相乘</span>
        grad <span class="token operator">=</span> grad_loss_sigmoid_wx <span class="token operator">*</span> grad_sigmoid_wx_wx
        grad <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>grad<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> grad_wx_w<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> grad
    
<span class="token comment"># 梯度更新</span>
<span class="token keyword">def</span> <span class="token function">diy_sgd</span><span class="token punctuation">(</span>grad<span class="token punctuation">,</span> weight<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> weight <span class="token operator">-</span> learning_rate <span class="token operator">*</span> grad
    
    
<span class="token comment"># adam梯度更新</span>
<span class="token keyword">def</span> <span class="token function">diy_adam</span><span class="token punctuation">(</span>weight<span class="token punctuation">,</span> grad<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">pass</span>
    

x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># input</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.01</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># output</span>

<span class="token comment"># torch实验</span>
torch_model <span class="token operator">=</span> TorchModel<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
torch_model_w <span class="token operator">=</span> torch_model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&quot;layer.weight&quot;</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch_model_w<span class="token punctuation">,</span> <span class="token string">&quot;初始化权重&quot;</span><span class="token punctuation">)</span>
numpy_model_w <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>torch_model_w<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># numpy array -&gt; torch tensor, unsqueeze的目的是增加一个batchsize维度</span>
torch_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
torch_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># torch的前向计算过程得到Loss</span>
torch_loss <span class="token operator">=</span> torch_model<span class="token punctuation">(</span>torch_x<span class="token punctuation">,</span> torch_y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;torch模型计算loss:&quot;</span><span class="token punctuation">,</span> torch_loss<span class="token punctuation">)</span>
<span class="token comment"># 手动实现Loss计算</span>
diy_model <span class="token operator">=</span> DiyModel<span class="token punctuation">(</span>numpy_model_w<span class="token punctuation">)</span>
diy_loss <span class="token operator">=</span> diy_model<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;diy模型计算Loss：&quot;</span><span class="token punctuation">,</span> diy_loss<span class="token punctuation">)</span>

<span class="token comment"># 设定优化器</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.1</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>torch_model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>
optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># pytorch反向传播</span>
torch_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch_model<span class="token punctuation">.</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>grad<span class="token punctuation">,</span> <span class="token string">&quot;torch 计算梯度&quot;</span><span class="token punctuation">)</span> <span class="token comment">#查看某层权重的梯度</span>

<span class="token comment"># 手动实现反向传播</span>
grad <span class="token operator">=</span> diy_model<span class="token punctuation">.</span>calculate_grad<span class="token punctuation">(</span>diy_model<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>grad<span class="token punctuation">,</span> <span class="token string">&quot;diy 计算梯度&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># torch梯度更新</span>
optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 查看更新后的权重</span>
update_torch_model_w <span class="token operator">=</span> torch_model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&quot;layer.weight&quot;</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>update_torch_model_w<span class="token punctuation">,</span> <span class="token string">&quot;torch更新后权重&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># 手动更新权重</span>
diy_update_w <span class="token operator">=</span> diy_sgd<span class="token punctuation">(</span>grad<span class="token punctuation">,</span> numpy_model_w<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>diy_update_w<span class="token punctuation">,</span> <span class="token string">&quot;diy更新权重&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><pre><code>tensor([[-0.0688, -0.1154,  0.3712, -0.1221],
        [ 0.1832,  0.1128, -0.3492,  0.2438],
        [-0.2641,  0.2777,  0.3455, -0.1716],
        [ 0.2766, -0.1304, -0.2022, -0.0633]]) 初始化权重
torch模型计算loss: tensor(0.3027, grad_fn=&lt;MseLossBackward0&gt;)
diy模型计算Loss： 0.3026517964997023
tensor([[0.0585, 0.1170, 0.1756, 0.2341],
        [0.0830, 0.1661, 0.2491, 0.3322],
        [0.0729, 0.1458, 0.2186, 0.2915],
        [0.0327, 0.0653, 0.0980, 0.1306]]) torch 计算梯度
[[0.05852284 0.11704567 0.17556851 0.23409135]
 [0.08304298 0.16608597 0.24912895 0.33217193]
 [0.07287766 0.14575531 0.21863297 0.29151063]
 [0.03265973 0.06531947 0.0979792  0.13063894]] diy 计算梯度
tensor([[-0.0747, -0.1271,  0.3536, -0.1455],
        [ 0.1749,  0.0962, -0.3741,  0.2106],
        [-0.2714,  0.2631,  0.3236, -0.2008],
        [ 0.2733, -0.1369, -0.2120, -0.0764]]) torch更新后权重
[[-0.07466543 -0.12709058  0.35364758 -0.14549667]
 [ 0.17487323  0.09616131 -0.3740775   0.2105791 ]
 [-0.27143701  0.26312841  0.32363521 -0.20075558]
 [ 0.27329445 -0.13691079 -0.21199815 -0.07640724]] diy更新权重
</code></pre><h2 id="激活函数" tabindex="-1"><a class="header-anchor" href="#激活函数" aria-hidden="true">#</a> 激活函数</h2><ul><li>为模型添加非线性因素，使模型具有拟合非线性函数的能力</li></ul><h3 id="sigmoid" tabindex="-1"><a class="header-anchor" href="#sigmoid" aria-hidden="true">#</a> Sigmoid</h3><p>一种非线性函数，将任意输入映射到0-1之间 缺点：</p><ol><li>计算耗时，包含指数运算</li><li>非0均值，会导致收敛慢</li><li>易造成梯度消失</li></ol>`,7),A=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mrow",null,[s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"x")])])])])]),s("annotation",{encoding:"application/x-tex"}," f(x)=\\frac{1}{1+e^{-x}} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.0908em","vertical-align":"-0.7693em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6973em"}},[s("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7693em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1),x=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")")])])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("mo",{stretchy:"false"},"("),s("mo",null,"−"),s("mn",null,"1"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},"("),s("mo",null,"−"),s("mn",null,"1"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"e"),s("mi",null,"x")]),s("mo",null,"+"),s("mn",null,"1"),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mrow",null,[s("mo",null,"−"),s("mn",null,"2")])]),s("msup",null,[s("mi",null,"e"),s("mi",null,"x")])])])])]),s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"x")])]),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mrow",null,[s("mo",null,"−"),s("mn",null,"2")])]),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mn",null,"2"),s("mi",null,"x")])]),s("msup",null,[s("mi",null,"e"),s("mi",null,"x")])])])])]),s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"x")])]),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mrow",null,[s("mo",null,"−"),s("mn",null,"1")])]),s("mo",null,"⋅"),s("mfrac",null,[s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"x")])]),s("mrow",null,[s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"x")])])])])])])])]),s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"−"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")")])])])])]),s("annotation",{encoding:"application/x-tex"}," \\begin{align*} f(x) &= (-1)(-1)(e^{x}+1)^{-2}e^{x} \\\\ &= (1+e^{-x})^{-2}e^{-2x}e^{x} \\\\ &= (1+e^{-x})^{-1} \\cdot \\frac{e^{-x}}{1+e^{-x}} \\\\ &= f(x)(1-f(x)) \\end{align*} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"7.0659em","vertical-align":"-3.2829em"}}),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-r"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"3.7829em"}},[s("span",{style:{top:"-6.3672em"}},[s("span",{class:"pstrut",style:{height:"3.4483em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-4.8431em"}},[s("span",{class:"pstrut",style:{height:"3.4483em"}}),s("span",{class:"mord"})]),s("span",{style:{top:"-2.7347em"}},[s("span",{class:"pstrut",style:{height:"3.4483em"}}),s("span",{class:"mord"})]),s("span",{style:{top:"-0.8254em"}},[s("span",{class:"pstrut",style:{height:"3.4483em"}}),s("span",{class:"mord"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"3.2829em"}},[s("span")])])])]),s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"3.7829em"}},[s("span",{style:{top:"-6.3672em"}},[s("span",{class:"pstrut",style:{height:"3.4483em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"−"),s("span",{class:"mord"},"1"),s("span",{class:"mclose"},")"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"−"),s("span",{class:"mord"},"1"),s("span",{class:"mclose"},")"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7144em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mtight"},"2")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7144em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])]),s("span",{style:{top:"-4.8431em"}},[s("span",{class:"pstrut",style:{height:"3.4483em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8213em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])]),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mtight"},"2")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mtight"},"2"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7144em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])]),s("span",{style:{top:"-2.7347em"}},[s("span",{class:"pstrut",style:{height:"3.4483em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8213em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])]),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mtight"},"1")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.4483em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6973em"}},[s("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7713em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7693em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])]),s("span",{style:{top:"-0.8254em"}},[s("span",{class:"pstrut",style:{height:"3.4483em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},"))")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"3.2829em"}},[s("span")])])])])])])])])])])],-1),w=s("h3",{id:"tanh",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#tanh","aria-hidden":"true"},"#"),n(" tanh")],-1),f=s("p",null,[n("以0为均值，解决了sigmoid的一定缺点，但是依然存在梯度消失问题，计算同样非常耗时 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"t"),s("mi",null,"a"),s("mi",null,"n"),s("mi",null,"h"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("mi",null,"s"),s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"h"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")")]),s("mrow",null,[s("mi",null,"c"),s("mi",null,"o"),s("mi",null,"s"),s("mi",null,"h"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")")])]),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("msup",null,[s("mi",null,"e"),s("mi",null,"x")]),s("mo",null,"−"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"x")])])]),s("mrow",null,[s("msup",null,[s("mi",null,"e"),s("mi",null,"x")]),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"x")])])])])]),s("annotation",{encoding:"application/x-tex"},"tanh(x) = \\frac{sinh(x)}{cosh(x)}=\\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"anh"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.53em","vertical-align":"-0.52em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.01em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"cos"),s("span",{class:"mord mathnormal mtight"},"h"),s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"mclose mtight"},")")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.485em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"s"),s("span",{class:"mord mathnormal mtight"},"inh"),s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"mclose mtight"},")")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.52em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.3907em","vertical-align":"-0.4033em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9874em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.5935em"}},[s("span",{style:{top:"-2.786em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])]),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7027em"}},[s("span",{style:{top:"-2.786em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7385em"}},[s("span",{style:{top:"-2.931em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])]),s("span",{class:"mbin mtight"},"−"),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8477em"}},[s("span",{style:{top:"-2.931em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4033em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])],-1),z=s("p",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"t"),s("mi",null,"a"),s("mi",null,"n"),s("mi",null,"h"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("mn",null,"1"),s("mo",null,"−"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mn",null,"2"),s("mi",null,"x")])])]),s("mrow",null,[s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mn",null,"2"),s("mi",null,"x")])])])]),s("mo",null,"−"),s("mn",null,"1"),s("mo",null,"="),s("mn",null,"2"),s("mo",{stretchy:"false"},"("),s("mfrac",null,[s("mn",null,"1"),s("mrow",null,[s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mn",null,"2"),s("mi",null,"x")])])])]),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mn",null,"2"),s("mi",null,"s"),s("mi",null,"i"),s("mi",null,"g"),s("mi",null,"m"),s("mi",null,"o"),s("mi",null,"i"),s("mi",null,"d"),s("mo",{stretchy:"false"},"("),s("mn",null,"2"),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mn",null,"1")]),s("annotation",{encoding:"application/x-tex"},"tanh(x)=\\frac{1-e^{-2x}}{1+e^{2x}}-1=2(\\frac{1}{1+e^{-2x}})=2sigmoid(2x)-1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"anh"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.4213em","vertical-align":"-0.4033em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.0179em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7463em"}},[s("span",{style:{top:"-2.786em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mbin mtight"},"−"),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8913em"}},[s("span",{style:{top:"-2.931em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mtight"},"2"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4033em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2484em","vertical-align":"-0.4033em"}}),s("span",{class:"mord"},"2"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8451em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7463em"}},[s("span",{style:{top:"-2.786em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mtight"},"2"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4033em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"2"),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g"),s("span",{class:"mord mathnormal"},"m"),s("span",{class:"mord mathnormal"},"o"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal"},"d"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"2"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"1")])])])],-1),_=s("h3",{id:"relu",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#relu","aria-hidden":"true"},"#"),n(" Relu")],-1),C=s("ul",null,[s("li",null,"在正区间不易发生梯度消失"),s("li",null,"计算速度非常快"),s("li",null,"一定程度上降低过拟合的风险")],-1),q=s("p",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"R"),s("mi",null,"e"),s("mi",null,"l"),s("mi",null,"u"),s("mo",null,"="),s("mi",null,"max"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("mn",null,"0"),s("mo",{separator:"true"},","),s("mi",null,"x"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"Relu=\\max(0, x)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop"},"max"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])])],-1),L=s("h3",{id:"softmax",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#softmax","aria-hidden":"true"},"#"),n(" Softmax")],-1),I=s("p",null,"softmax用于多分类过程中，它将多个神经元的输出，映射到(0, 1)区间内，可以看成概率来理解，从而来进行多分类。",-1),F=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"S"),s("mi",null,"i")]),s("mo",null,"="),s("mfrac",null,[s("msup",null,[s("mi",null,"e"),s("mi",null,"i")]),s("mrow",null,[s("munder",null,[s("mo",null,"∑"),s("mi",null,"j")]),s("msup",null,[s("mi",null,"e"),s("mi",null,"j")])])])]),s("annotation",{encoding:"application/x-tex"}," S_{i}=\\frac{e^{i}}{\\sum_{j}{e^{j}}} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.6235em","vertical-align":"-1.1218em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.5017em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mop"},[s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.162em"}},[s("span",{style:{top:"-2.4003em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4358em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7507em"}},[s("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8247em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.1218em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1),M=s("h2",{id:"损失函数",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#损失函数","aria-hidden":"true"},"#"),n(" 损失函数")],-1),B=s("h3",{id:"均方差-mse-mean-square-error",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#均方差-mse-mean-square-error","aria-hidden":"true"},"#"),n(" 均方差 MSE mean square error")],-1),R=s("p",null,"MSE是最直观的损失函数，计算预测值和真实值之间的欧式距离。预测值和真实值越接近，均方差越小。",-1),H=s("p",null,"mse常用于线性回归，即函数拟合，公式如下：",-1),K=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"l"),s("mi",null,"o"),s("mi",null,"s"),s("mi",null,"s"),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mn",null,"2")]),s("mo",{stretchy:"false"},"("),s("mi",null,"z"),s("mo",null,"−"),s("mi",null,"y"),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"}," loss=\\frac{1}{2}(z-y)^{2} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mord mathnormal"},"oss"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.0074em","vertical-align":"-0.686em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"2")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1141em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])])])])])],-1),Q=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"J"),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mrow",null,[s("mn",null,"2"),s("mi",null,"m")])]),s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"i"),s("mo",null,"="),s("mn",null,"1")]),s("mi",null,"m")]),s("msup",null,[s("mrow",null,[s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"z"),s("mi",null,"i")]),s("mo",null,"−"),s("msub",null,[s("mi",null,"y"),s("mi",null,"i")]),s("mo",{stretchy:"false"},")")]),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"}," J=\\frac{1}{2m}\\sum^{m}_{i=1}{(z_{i}-y_{i})}^{2} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.09618em"}},"J"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.9291em","vertical-align":"-1.2777em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"2"),s("span",{class:"mord mathnormal"},"m")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6514em"}},[s("span",{style:{top:"-1.8723em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"1")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"m")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2777em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.044em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.954em"}},[s("span",{style:{top:"-3.2029em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])])])])])],-1),W=s("h3",{id:"交叉熵-cross-entropy",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#交叉熵-cross-entropy","aria-hidden":"true"},"#"),n(" 交叉熵 Cross Entropy")],-1),P=s("p",null,"常用于分类任务",-1),S=s("p",null,"分类任务中，网络输出经常是所有类别上的概率分布",-1),T=s("p",null,"公式：",-1),N=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"H"),s("mo",{stretchy:"false"},"("),s("mi",null,"p"),s("mo",{separator:"true"},","),s("mi",null,"q"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mo",null,"−"),s("munder",null,[s("mo",null,"∑"),s("mi",null,"x")]),s("mi",null,"p"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mi",null,"log"),s("mo",null,"⁡"),s("mi",null,"q"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," H(p,q)=-\\sum_{x}p(x)\\log q(x) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"q"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.3em","vertical-align":"-1.25em"}}),s("span",{class:"mord"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.05em"}},[s("span",{style:{top:"-1.9em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.25em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[n("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"q"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])])])],-1),V=s("p",null,[n("假设一个三分类任务，某样本的正确标签是第一类：则"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"p"),s("mo",null,"="),s("mo",{stretchy:"false"},"["),s("mn",null,"1"),s("mo",{separator:"true"},","),s("mn",null,"0"),s("mo",{separator:"true"},","),s("mn",null,"0"),s("mo",{stretchy:"false"},"]")]),s("annotation",{encoding:"application/x-tex"},"p=[1,0,0]")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord"},"1"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"0"),s("span",{class:"mclose"},"]")])])]),n("，模型预测值假设为"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",{stretchy:"false"},"["),s("mn",null,"0.5"),s("mo",{separator:"true"},","),s("mn",null,"0.4"),s("mo",{separator:"true"},","),s("mn",null,"0.1"),s("mo",{stretchy:"false"},"]")]),s("annotation",{encoding:"application/x-tex"},"[0.5,0.4,0.1]")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord"},"0.5"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"0.4"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"0.1"),s("span",{class:"mclose"},"]")])])]),n("，则交叉熵计算如下：")],-1),Y=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"H"),s("mo",{stretchy:"false"},"("),s("mi",null,"p"),s("mo",null,"="),s("mo",{stretchy:"false"},"["),s("mn",null,"1"),s("mo",{separator:"true"},","),s("mn",null,"0"),s("mo",{separator:"true"},","),s("mn",null,"0"),s("mo",{stretchy:"false"},"]"),s("mo",{separator:"true"},","),s("mi",null,"q"),s("mo",null,"="),s("mo",{stretchy:"false"},"["),s("mn",null,"0"),s("mo",{separator:"true"},","),s("mn",null,"5"),s("mo",{separator:"true"},","),s("mn",null,"0.4"),s("mo",{separator:"true"},","),s("mn",null,"0.1"),s("mo",{stretchy:"false"},"]"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mo",null,"−"),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"∗"),s("mi",null,"log"),s("mo",null,"⁡"),s("mn",null,"0.5"),s("mo",null,"+"),s("mn",null,"0"),s("mo",null,"∗"),s("mi",null,"log"),s("mo",null,"⁡"),s("mn",null,"0.4"),s("mo",null,"+"),s("mn",null,"0"),s("mo",null,"∗"),s("mi",null,"log"),s("mo",null,"⁡"),s("mn",null,"0.1"),s("mo",{stretchy:"false"},")"),s("mo",null,"≈"),s("mn",null,"0.3")]),s("annotation",{encoding:"application/x-tex"}," H(p=[1,0,0],q=[0,5,0.4,0.1])=-(1 * \\log 0.5 + 0 * \\log 0.4 + 0 * \\log 0.1) \\approx 0.3 ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord"},"1"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"0"),s("span",{class:"mclose"},"]"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"q"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"5"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"0.4"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"0.1"),s("span",{class:"mclose"},"])"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"−"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"∗"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mop"},[n("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"0.5"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"0"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"∗"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mop"},[n("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"0.4"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"0"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"∗"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop"},[n("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"0.1"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"≈"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"0.3")])])])])],-1),j=s("h3",{id:"指数损失函数",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#指数损失函数","aria-hidden":"true"},"#"),n(" 指数损失函数")],-1),E=s("p",null,"指数损失函数的标准形式如下：",-1),X=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"L"),s("mo",{stretchy:"false"},"("),s("mi",null,"Y"),s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"X"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"y"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"X"),s("mo",{stretchy:"false"},")")])])]),s("annotation",{encoding:"application/x-tex"}," L(Y|f(X)) = e^{-yf(X)} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"Y"),s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mclose"},"))"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.938em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mclose mtight"},")")])])])])])])])])])])])])],-1),D=s("p",null,"特点：对离群点、噪声非常敏感。经常用在AdaBoost算法中。",-1),G=s("h3",{id:"hinge损失函数",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#hinge损失函数","aria-hidden":"true"},"#"),n(" Hinge损失函数")],-1),U=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"L"),s("mo",{stretchy:"false"},"("),s("mi",null,"y"),s("mo",{separator:"true"},","),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"m"),s("mi",null,"a"),s("mi",null,"x"),s("mo",{stretchy:"false"},"("),s("mn",null,"0"),s("mo",{separator:"true"},","),s("mn",null,"1"),s("mo",null,"−"),s("mi",null,"y"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," L(y,f(x))=max(0, 1-yf(x)) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},"))"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"ma"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},"))")])])])])],-1),Z=s("p",null,"特点：",-1),J=s("ul",null,[s("li",null,"hinge损失函数表示如果分类正确，损失为0，否则损失就为1-yf(x)。SVM就是使用这个损失函数。"),s("li",null,"一般的f(x)是预测值，在-1到1之间，y是目标值（-1或1）。其含义是，f(x)的值在-1和1之间就可以了，并不鼓励|f(x)|>1，即并不鼓励分类器过度自信，让某个正确分类的样本距离分割线超过1并不会有任何奖励，从而使分类器可以更专注与整体的误差。"),s("li",null,"健壮性相对较高，对异常点、噪声不敏感，但它没太好的概率解释。")],-1),O=s("h3",{id:"log对数损失函数",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#log对数损失函数","aria-hidden":"true"},"#"),n(" log对数损失函数")],-1),$=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"L"),s("mo",{stretchy:"false"},"("),s("mi",null,"y"),s("mo",{separator:"true"},","),s("mi",null,"p"),s("mo",{stretchy:"false"},"("),s("mi",null,"y"),s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mo",null,"−"),s("mi",null,"log"),s("mo",null,"⁡"),s("mi",null,"p"),s("mo",{stretchy:"false"},"("),s("mi",null,"y"),s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"x"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," L(y,p(y|x))=-\\log p(y|x) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},"))"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[n("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])])])],-1),ss=s("p",null,"特点：",-1),ns=s("ul",null,[s("li",null,"log对数损失函数能非常好的表征概率分布，在很多场景尤其是多分类，如果需要知道结果属于每个类别的置信度，那它非常适合。"),s("li",null,"健壮性不强，相比于hinge loss对噪声更敏感。"),s("li",null,"逻辑回归的损失函数就是log对数损失函数。")],-1),as=s("h3",{id:"_0-1损失函数-zero-one-loss",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#_0-1损失函数-zero-one-loss","aria-hidden":"true"},"#"),n(" 0/1损失函数 zero-one loss")],-1),ts=s("p",null,"0-1损失是指预测值和目标值不相等为1，否则为0：",-1),ls=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{rowspacing:"0.25em",columnalign:"right",columnspacing:""},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mtable",{rowspacing:"0.25em",columnalign:"right",columnspacing:""},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mi",null,"L"),s("mo",{stretchy:"false"},"("),s("mi",null,"y"),s("mo",{separator:"true"},","),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mrow",null,[s("mo",{fence:"true"},"{"),s("mtable",{rowspacing:"0.16em",columnalign:"left left",columnspacing:"1em"},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mrow",null,[s("mn",null,"1"),s("mo",{separator:"true"},",")])])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mrow",null,[s("mi",null,"y"),s("mo",{mathvariant:"normal"},"≠"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")")])])])]),s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mrow",null,[s("mn",null,"0"),s("mo",{separator:"true"},",")])])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mrow",null,[s("mi",null,"y"),s("mo",null,"="),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")")])])])])])])])])])])])])])])]),s("annotation",{encoding:"application/x-tex"}," \\begin{align*} \\begin{split} L(y,f(x))= \\left\\{ \\begin{array}{ll} 1, & y \\neq f(x) \\\\ 0, & y = f(x) \\end{array} \\right. \\end{split} \\end{align*} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3em","vertical-align":"-1.25em"}}),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-r"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.75em"}},[s("span",{style:{top:"-3.75em"}},[s("span",{class:"pstrut",style:{height:"3.6em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-r"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6em"}},[s("span",{style:{top:"-3.6em"}},[s("span",{class:"pstrut",style:{height:"3.45em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},"))"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size3"},"{")]),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"arraycolsep",style:{width:"0.5em"}}),s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.45em"}},[s("span",{style:{top:"-3.61em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1"),s("span",{class:"mpunct"},",")])]),s("span",{style:{top:"-2.41em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},",")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.95em"}},[s("span")])])])]),s("span",{class:"arraycolsep",style:{width:"0.5em"}}),s("span",{class:"arraycolsep",style:{width:"0.5em"}}),s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.45em"}},[s("span",{style:{top:"-3.61em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},[s("span",{class:"mrel"},[s("span",{class:"mord vbox"},[s("span",{class:"thinbox"},[s("span",{class:"rlap"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"inner"},[s("span",{class:"mord"},[s("span",{class:"mrel"},"")])]),s("span",{class:"fix"})])])])]),s("span",{class:"mrel"},"=")]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-2.41em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.95em"}},[s("span")])])])]),s("span",{class:"arraycolsep",style:{width:"0.5em"}})])]),s("span",{class:"mclose nulldelimiter"})])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.1em"}},[s("span")])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.25em"}},[s("span")])])])])])])])])])])],-1),ps=s("p",null,"特点：",-1),es=s("ul",null,[s("li",null,"0-1损失函数直接对应分类判断错误的个数，但是它是一个非凸函数，不太适用。"),s("li",null,[n("感知机就是使用的这种损失函数。但是相等这个条件太过严格，因此可以放宽条件，即满足"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"y"),s("mo",null,"−"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"∣"),s("mo",null,"<"),s("mi",null,"T")]),s("annotation",{encoding:"application/x-tex"},"|y-f(x)| < T")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"∣"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"<"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"T")])])]),n("时认为相等，")])],-1),cs=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{rowspacing:"0.25em",columnalign:"right",columnspacing:""},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mtable",{rowspacing:"0.25em",columnalign:"right",columnspacing:""},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mi",null,"L"),s("mo",{stretchy:"false"},"("),s("mi",null,"y"),s("mo",{separator:"true"},","),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")"),s("mrow",null,[s("mo",{fence:"true"},"{"),s("mtable",{rowspacing:"0.16em",columnalign:"left left",columnspacing:"1em"},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mrow",null,[s("mn",null,"1"),s("mo",{separator:"true"},",")])])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mrow",null,[s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"y"),s("mo",null,"−"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"∣"),s("mo",null,"≥"),s("mi",null,"T")])])])]),s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mrow",null,[s("mn",null,"0"),s("mo",{separator:"true"},",")])])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mrow",null,[s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"y"),s("mo",null,"="),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"∣"),s("mo",null,"<"),s("mi",null,"T")])])])])])])])])])])])])])])]),s("annotation",{encoding:"application/x-tex"}," \\begin{align*} \\begin{split} L(y,f(x)) \\left\\{ \\begin{array}{ll} 1, & |y-f(x)| \\geq T \\\\ 0, & |y=f(x)| < T \\end{array} \\right. \\end{split} \\end{align*} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3em","vertical-align":"-1.25em"}}),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-r"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.75em"}},[s("span",{style:{top:"-3.75em"}},[s("span",{class:"pstrut",style:{height:"3.6em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-r"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6em"}},[s("span",{style:{top:"-3.6em"}},[s("span",{class:"pstrut",style:{height:"3.45em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},"))"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size3"},"{")]),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"arraycolsep",style:{width:"0.5em"}}),s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.45em"}},[s("span",{style:{top:"-3.61em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1"),s("span",{class:"mpunct"},",")])]),s("span",{style:{top:"-2.41em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},",")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.95em"}},[s("span")])])])]),s("span",{class:"arraycolsep",style:{width:"0.5em"}}),s("span",{class:"arraycolsep",style:{width:"0.5em"}}),s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.45em"}},[s("span",{style:{top:"-3.61em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"∣"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"≥"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"T")])]),s("span",{style:{top:"-2.41em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"∣"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"<"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"T")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.95em"}},[s("span")])])])]),s("span",{class:"arraycolsep",style:{width:"0.5em"}})])]),s("span",{class:"mclose nulldelimiter"})])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.1em"}},[s("span")])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.25em"}},[s("span")])])])])])])])])])])],-1),os=l(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token triple-quoted-string string">&#39;&#39;&#39;
手动实现交叉熵的计算
&#39;&#39;&#39;</span>

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># 使用torch计算交叉熵</span>
ce_loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 假设有3个样本，每个都在做3分类</span>
pred <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                         <span class="token punctuation">[</span><span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                         <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 正确的类别分别为1,2,0</span>
target <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
loss <span class="token operator">=</span> ce_loss<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">,</span> <span class="token string">&quot;torch输出交叉熵&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># 实现softmax函数</span>
<span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>matrix<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>matrix<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>matrix<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 验证softmax函数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>softmax<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 将输入转化为onehot矩阵</span>
<span class="token keyword">def</span> <span class="token function">to_one_hot</span><span class="token punctuation">(</span>target<span class="token punctuation">,</span> shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
    one_hot_target <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> t <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>
        one_hot_target<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> one_hot_target

<span class="token comment"># 手动实现交叉熵</span>
<span class="token keyword">def</span> <span class="token function">cross_entropy</span><span class="token punctuation">(</span>pred<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    batch_size<span class="token punctuation">,</span> class_num <span class="token operator">=</span> pred<span class="token punctuation">.</span>shape
    pred <span class="token operator">=</span> softmax<span class="token punctuation">(</span>pred<span class="token punctuation">)</span>
    target <span class="token operator">=</span> to_one_hot<span class="token punctuation">(</span>target<span class="token punctuation">,</span> pred<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    entropy <span class="token operator">=</span> <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>target <span class="token operator">*</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>entropy<span class="token punctuation">)</span> <span class="token operator">/</span> batch_size

<span class="token keyword">print</span><span class="token punctuation">(</span>cross_entropy<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;手动实现交叉熵&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><pre><code>tensor(1.0414) torch输出交叉熵
tensor([[0.3548, 0.2905, 0.3548],
        [0.4005, 0.1989, 0.4005],
        [0.3780, 0.3420, 0.2800]])
[[0.3547696  0.2904608  0.3547696 ]
 [0.40054712 0.19890581 0.40054712]
 [0.37797815 0.34200877 0.2800131 ]]
1.0413764715194702 手动实现交叉熵
</code></pre><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token triple-quoted-string string">&#39;&#39;&#39;
softmax的计算
&#39;&#39;&#39;</span>

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># e的1次方</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token comment">#torch实现的softmax</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 自己实现的softmax</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>softmax<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><pre><code>2.718281828459045
tensor([[0.0321, 0.0871, 0.2369, 0.6439]])
[[0.0320586  0.08714432 0.23688282 0.64391426]]
</code></pre><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token triple-quoted-string string">&#39;&#39;&#39;
numpy手动实现模拟一个线性层
&#39;&#39;&#39;</span>

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># 搭建一个2层的神经网络模型</span>
<span class="token comment"># 每层都是线性层</span>
<span class="token keyword">class</span> <span class="token class-name">TorchModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size1<span class="token punctuation">,</span> hidden_size2<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TorchModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size1<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size1<span class="token punctuation">,</span> hidden_size2<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># shape: (batch_size, input_size) =&gt; (batch_size, hidden_size1)</span>
        y_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>hidden<span class="token punctuation">)</span> <span class="token comment"># shape: (batch_size, hidden_size1) =&gt; (batch_size, hidden_size2)</span>
        <span class="token keyword">return</span> y_pred

<span class="token comment"># 自定义模型</span>
<span class="token keyword">class</span> <span class="token class-name">DiyModel</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> w1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span> b2<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>w1 <span class="token operator">=</span> w1
        self<span class="token punctuation">.</span>b1 <span class="token operator">=</span> b1
        self<span class="token punctuation">.</span>w2 <span class="token operator">=</span> w2
        self<span class="token punctuation">.</span>b2 <span class="token operator">=</span> b2
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        hidden <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>w1<span class="token punctuation">.</span>T<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b1
        y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>hidden<span class="token punctuation">,</span> self<span class="token punctuation">.</span>w2<span class="token punctuation">.</span>T<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b2
        <span class="token keyword">return</span> y_pred

<span class="token comment"># 随便准备一个网络输入</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">34.1</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">1.2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 建立一个torch模型</span>
torch_model <span class="token operator">=</span> TorchModel<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch_model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;--------------&quot;</span><span class="token punctuation">)</span>
<span class="token comment"># 打印模型权重，权重为随机初始化</span>
torch_model_w1 <span class="token operator">=</span> torch_model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&quot;layer1.weight&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch_model_b1 <span class="token operator">=</span> torch_model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&quot;layer1.bias&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch_model_w2 <span class="token operator">=</span> torch_model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&quot;layer2.weight&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch_model_b2 <span class="token operator">=</span> torch_model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&quot;layer2.bias&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch_model_w1<span class="token punctuation">,</span> <span class="token string">&quot;torch w1 权重&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch_model_b1<span class="token punctuation">,</span> <span class="token string">&quot;torch b1 权重&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;-------------&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch_model_w2<span class="token punctuation">,</span> <span class="token string">&quot;torch w2 权重&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch_model_b2<span class="token punctuation">,</span> <span class="token string">&quot;torch b2 权重&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;-------------&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># 使用torch模型做预测</span>

torch_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">)</span>
y_pred <span class="token operator">=</span> torch_model<span class="token punctuation">(</span>torch_x<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;torch模型预测结果：&quot;</span><span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>

<span class="token comment"># 把torch模型权重拿过来自己实现计算过程</span>
diy_model <span class="token operator">=</span> DiyModel<span class="token punctuation">(</span>torch_model_w1<span class="token punctuation">,</span> torch_model_b1<span class="token punctuation">,</span> torch_model_w2<span class="token punctuation">,</span> torch_model_b2<span class="token punctuation">)</span>

<span class="token comment"># 用自己的模型来预测</span>
y_pred_diy <span class="token operator">=</span> diy_model<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;diy模型预测结果：&quot;</span><span class="token punctuation">,</span> y_pred_diy<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><pre><code>OrderedDict([(&#39;layer1.weight&#39;, tensor([[ 0.3548,  0.3213,  0.2949],
        [-0.1772, -0.4781, -0.3800],
        [-0.1690,  0.4936,  0.5701],
        [ 0.5164,  0.0919,  0.3176],
        [-0.3879, -0.2090, -0.1994]])), (&#39;layer1.bias&#39;, tensor([ 0.0356,  0.1869, -0.2310,  0.0813, -0.1616])), (&#39;layer2.weight&#39;, tensor([[-0.1867, -0.2119, -0.2518, -0.0141,  0.0062],
        [ 0.0821,  0.0376, -0.0804, -0.2649,  0.1395]])), (&#39;layer2.bias&#39;, tensor([ 0.0076, -0.4094]))])
--------------
[[ 0.35481602  0.32126385  0.29487878]
 [-0.17720988 -0.4781404  -0.38002336]
 [-0.16895026  0.49363816  0.57008505]
 [ 0.51635015  0.09194171  0.31759936]
 [-0.38786483 -0.20902103 -0.1993975 ]] torch w1 权重
[ 0.03564513  0.1868751  -0.2310259   0.081294   -0.161565  ] torch b1 权重
-------------
[[-0.18666321 -0.21191819 -0.25180575 -0.01410726  0.00623879]
 [ 0.08212394  0.0376336  -0.08036387 -0.26493412  0.13951719]] torch w2 权重
[ 0.00758311 -0.40939885] torch b2 权重
-------------
torch模型预测结果： tensor([[-0.0150, -5.9087]], grad_fn=&lt;AddmmBackward0&gt;)
diy模型预测结果： [[-0.01495245 -5.90873057]]


C:\\Users\\34220\\AppData\\Local\\Temp\\ipykernel_18036\\3223465895.py:56: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)
  torch_x = torch.FloatTensor([x])
</code></pre><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token triple-quoted-string string">&#39;&#39;&#39;
Gradient Descent
&#39;&#39;&#39;</span>

<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> math

X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">,</span> <span class="token number">0.03</span><span class="token punctuation">,</span> <span class="token number">0.04</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.06</span><span class="token punctuation">,</span> <span class="token number">0.07</span><span class="token punctuation">,</span> <span class="token number">0.08</span><span class="token punctuation">,</span> <span class="token number">0.09</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.11</span><span class="token punctuation">,</span> <span class="token number">0.12</span><span class="token punctuation">,</span> <span class="token number">0.13</span><span class="token punctuation">,</span> <span class="token number">0.14</span><span class="token punctuation">,</span> <span class="token number">0.15</span><span class="token punctuation">,</span> <span class="token number">0.16</span><span class="token punctuation">,</span> <span class="token number">0.17</span><span class="token punctuation">,</span> <span class="token number">0.18</span><span class="token punctuation">,</span> <span class="token number">0.19</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.21</span><span class="token punctuation">,</span> <span class="token number">0.22</span><span class="token punctuation">,</span> <span class="token number">0.23</span><span class="token punctuation">,</span> <span class="token number">0.24</span><span class="token punctuation">,</span> <span class="token number">0.25</span><span class="token punctuation">,</span> <span class="token number">0.26</span><span class="token punctuation">,</span> <span class="token number">0.27</span><span class="token punctuation">,</span> <span class="token number">0.28</span><span class="token punctuation">,</span> <span class="token number">0.29</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.31</span><span class="token punctuation">,</span> <span class="token number">0.32</span><span class="token punctuation">,</span> <span class="token number">0.33</span><span class="token punctuation">,</span> <span class="token number">0.34</span><span class="token punctuation">,</span> <span class="token number">0.35000000000000003</span><span class="token punctuation">,</span> <span class="token number">0.36</span><span class="token punctuation">,</span> <span class="token number">0.37</span><span class="token punctuation">,</span> <span class="token number">0.38</span><span class="token punctuation">,</span> <span class="token number">0.39</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.41000000000000003</span><span class="token punctuation">,</span> <span class="token number">0.42</span><span class="token punctuation">,</span> <span class="token number">0.43</span><span class="token punctuation">,</span> <span class="token number">0.44</span><span class="token punctuation">,</span> <span class="token number">0.45</span><span class="token punctuation">,</span> <span class="token number">0.46</span><span class="token punctuation">,</span> <span class="token number">0.47000000000000003</span><span class="token punctuation">,</span> <span class="token number">0.48</span><span class="token punctuation">,</span> <span class="token number">0.49</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.51</span><span class="token punctuation">,</span> <span class="token number">0.52</span><span class="token punctuation">,</span> <span class="token number">0.53</span><span class="token punctuation">,</span> <span class="token number">0.54</span><span class="token punctuation">,</span> <span class="token number">0.55</span><span class="token punctuation">,</span> <span class="token number">0.56</span><span class="token punctuation">,</span> <span class="token number">0.5700000000000001</span><span class="token punctuation">,</span> <span class="token number">0.58</span><span class="token punctuation">,</span> <span class="token number">0.59</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.61</span><span class="token punctuation">,</span> <span class="token number">0.62</span><span class="token punctuation">,</span> <span class="token number">0.63</span><span class="token punctuation">,</span> <span class="token number">0.64</span><span class="token punctuation">,</span> <span class="token number">0.65</span><span class="token punctuation">,</span> <span class="token number">0.66</span><span class="token punctuation">,</span> <span class="token number">0.67</span><span class="token punctuation">,</span> <span class="token number">0.68</span><span class="token punctuation">,</span> <span class="token number">0.6900000000000001</span><span class="token punctuation">,</span> <span class="token number">0.7000000000000001</span><span class="token punctuation">,</span> <span class="token number">0.71</span><span class="token punctuation">,</span> <span class="token number">0.72</span><span class="token punctuation">,</span> <span class="token number">0.73</span><span class="token punctuation">,</span> <span class="token number">0.74</span><span class="token punctuation">,</span> <span class="token number">0.75</span><span class="token punctuation">,</span> <span class="token number">0.76</span><span class="token punctuation">,</span> <span class="token number">0.77</span><span class="token punctuation">,</span> <span class="token number">0.78</span><span class="token punctuation">,</span> <span class="token number">0.79</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">,</span> <span class="token number">0.81</span><span class="token punctuation">,</span> <span class="token number">0.8200000000000001</span><span class="token punctuation">,</span> <span class="token number">0.8300000000000001</span><span class="token punctuation">,</span> <span class="token number">0.84</span><span class="token punctuation">,</span> <span class="token number">0.85</span><span class="token punctuation">,</span> <span class="token number">0.86</span><span class="token punctuation">,</span> <span class="token number">0.87</span><span class="token punctuation">,</span> <span class="token number">0.88</span><span class="token punctuation">,</span> <span class="token number">0.89</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token number">0.91</span><span class="token punctuation">,</span> <span class="token number">0.92</span><span class="token punctuation">,</span> <span class="token number">0.93</span><span class="token punctuation">,</span> <span class="token number">0.9400000000000001</span><span class="token punctuation">,</span> <span class="token number">0.9500000000000001</span><span class="token punctuation">,</span> <span class="token number">0.96</span><span class="token punctuation">,</span> <span class="token number">0.97</span><span class="token punctuation">,</span> <span class="token number">0.98</span><span class="token punctuation">,</span> <span class="token number">0.99</span><span class="token punctuation">]</span>
Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">4.0</span><span class="token punctuation">,</span> <span class="token number">4.0302</span><span class="token punctuation">,</span> <span class="token number">4.0608</span><span class="token punctuation">,</span> <span class="token number">4.0918</span><span class="token punctuation">,</span> <span class="token number">4.1232</span><span class="token punctuation">,</span> <span class="token number">4.155</span><span class="token punctuation">,</span> <span class="token number">4.1872</span><span class="token punctuation">,</span> <span class="token number">4.2198</span><span class="token punctuation">,</span> <span class="token number">4.2528</span><span class="token punctuation">,</span> <span class="token number">4.2862</span><span class="token punctuation">,</span> <span class="token number">4.32</span><span class="token punctuation">,</span> <span class="token number">4.3542</span><span class="token punctuation">,</span> <span class="token number">4.3888</span><span class="token punctuation">,</span> <span class="token number">4.4238</span><span class="token punctuation">,</span> <span class="token number">4.4592</span><span class="token punctuation">,</span> <span class="token number">4.495</span><span class="token punctuation">,</span> <span class="token number">4.5312</span><span class="token punctuation">,</span> <span class="token number">4.5678</span><span class="token punctuation">,</span> <span class="token number">4.6048</span><span class="token punctuation">,</span> <span class="token number">4.6422</span><span class="token punctuation">,</span> <span class="token number">4.68</span><span class="token punctuation">,</span> <span class="token number">4.7181999999999995</span><span class="token punctuation">,</span> <span class="token number">4.7568</span><span class="token punctuation">,</span> <span class="token number">4.7958</span><span class="token punctuation">,</span> <span class="token number">4.8352</span><span class="token punctuation">,</span> <span class="token number">4.875</span><span class="token punctuation">,</span> <span class="token number">4.9152000000000005</span><span class="token punctuation">,</span> <span class="token number">4.9558</span><span class="token punctuation">,</span> <span class="token number">4.9968</span><span class="token punctuation">,</span> <span class="token number">5.0382</span><span class="token punctuation">,</span> <span class="token number">5.08</span><span class="token punctuation">,</span> <span class="token number">5.122199999999999</span><span class="token punctuation">,</span> <span class="token number">5.1648</span><span class="token punctuation">,</span> <span class="token number">5.2078</span><span class="token punctuation">,</span> <span class="token number">5.2512</span><span class="token punctuation">,</span> <span class="token number">5.295</span><span class="token punctuation">,</span> <span class="token number">5.3392</span><span class="token punctuation">,</span> <span class="token number">5.3838</span><span class="token punctuation">,</span> <span class="token number">5.4288</span><span class="token punctuation">,</span> <span class="token number">5.4742</span><span class="token punctuation">,</span> <span class="token number">5.5200000000000005</span><span class="token punctuation">,</span> <span class="token number">5.5662</span><span class="token punctuation">,</span> <span class="token number">5.6128</span><span class="token punctuation">,</span> <span class="token number">5.6598</span><span class="token punctuation">,</span> <span class="token number">5.7072</span><span class="token punctuation">,</span> <span class="token number">5.755</span><span class="token punctuation">,</span> <span class="token number">5.8032</span><span class="token punctuation">,</span> <span class="token number">5.851800000000001</span><span class="token punctuation">,</span> <span class="token number">5.9008</span><span class="token punctuation">,</span> <span class="token number">5.9502</span><span class="token punctuation">,</span> <span class="token number">6.0</span><span class="token punctuation">,</span> <span class="token number">6.0502</span><span class="token punctuation">,</span> <span class="token number">6.1008</span><span class="token punctuation">,</span> <span class="token number">6.1518</span><span class="token punctuation">,</span> <span class="token number">6.203200000000001</span><span class="token punctuation">,</span> <span class="token number">6.255000000000001</span><span class="token punctuation">,</span> <span class="token number">6.3072</span><span class="token punctuation">,</span> <span class="token number">6.3598</span><span class="token punctuation">,</span> <span class="token number">6.4128</span><span class="token punctuation">,</span> <span class="token number">6.4662</span><span class="token punctuation">,</span> <span class="token number">6.52</span><span class="token punctuation">,</span> <span class="token number">6.5742</span><span class="token punctuation">,</span> <span class="token number">6.6288</span><span class="token punctuation">,</span> <span class="token number">6.6838</span><span class="token punctuation">,</span> <span class="token number">6.7392</span><span class="token punctuation">,</span> <span class="token number">6.795</span><span class="token punctuation">,</span> <span class="token number">6.8512</span><span class="token punctuation">,</span> <span class="token number">6.9078</span><span class="token punctuation">,</span> <span class="token number">6.9648</span><span class="token punctuation">,</span> <span class="token number">7.022200000000001</span><span class="token punctuation">,</span> <span class="token number">7.08</span><span class="token punctuation">,</span> <span class="token number">7.138199999999999</span><span class="token punctuation">,</span> <span class="token number">7.1968</span><span class="token punctuation">,</span> <span class="token number">7.2558</span><span class="token punctuation">,</span> <span class="token number">7.3152</span><span class="token punctuation">,</span> <span class="token number">7.375</span><span class="token punctuation">,</span> <span class="token number">7.4352</span><span class="token punctuation">,</span> <span class="token number">7.4958</span><span class="token punctuation">,</span> <span class="token number">7.5568</span><span class="token punctuation">,</span> <span class="token number">7.6182</span><span class="token punctuation">,</span> <span class="token number">7.680000000000001</span><span class="token punctuation">,</span> <span class="token number">7.7422</span><span class="token punctuation">,</span> <span class="token number">7.8048</span><span class="token punctuation">,</span> <span class="token number">7.867800000000001</span><span class="token punctuation">,</span> <span class="token number">7.9312</span><span class="token punctuation">,</span> <span class="token number">7.994999999999999</span><span class="token punctuation">,</span> <span class="token number">8.0592</span><span class="token punctuation">,</span> <span class="token number">8.1238</span><span class="token punctuation">,</span> <span class="token number">8.1888</span><span class="token punctuation">,</span> <span class="token number">8.2542</span><span class="token punctuation">,</span> <span class="token number">8.32</span><span class="token punctuation">,</span> <span class="token number">8.3862</span><span class="token punctuation">,</span> <span class="token number">8.4528</span><span class="token punctuation">,</span> <span class="token number">8.5198</span><span class="token punctuation">,</span> <span class="token number">8.587200000000001</span><span class="token punctuation">,</span> <span class="token number">8.655000000000001</span><span class="token punctuation">,</span> <span class="token number">8.7232</span><span class="token punctuation">,</span> <span class="token number">8.7918</span><span class="token punctuation">,</span> <span class="token number">8.8608</span><span class="token punctuation">,</span> <span class="token number">8.9302</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">func</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> w1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span> w3<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> w1 <span class="token operator">*</span> x <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">+</span> w2 <span class="token operator">*</span> x <span class="token operator">+</span> w3

<span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y_true<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y_true<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>

<span class="token comment"># 权重随机初始化</span>
w1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span> w3 <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span>

<span class="token comment"># 学习率</span>
lr <span class="token operator">=</span> <span class="token number">0.01</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    epoch_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> x<span class="token punctuation">,</span> y_true <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y_pred <span class="token operator">=</span> func<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span> w3<span class="token punctuation">)</span>
        epoch_loss <span class="token operator">+=</span> loss<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y_true<span class="token punctuation">)</span>
        <span class="token comment"># 梯度计算</span>
        grad_w1 <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y_true<span class="token punctuation">)</span> <span class="token operator">*</span> x <span class="token operator">**</span> <span class="token number">2</span>
        grad_w2 <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y_true<span class="token punctuation">)</span> <span class="token operator">*</span> x
        grad_w3 <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y_true<span class="token punctuation">)</span>
        
        <span class="token comment"># 根据梯度修改权重（优化器）</span>
        w1 <span class="token operator">=</span> w1 <span class="token operator">-</span> lr <span class="token operator">*</span> grad_w1
        w2 <span class="token operator">=</span> w2 <span class="token operator">-</span> lr <span class="token operator">*</span> grad_w2
        w3 <span class="token operator">=</span> w3 <span class="token operator">-</span> lr <span class="token operator">*</span> grad_w3
    
    epoch_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;第%d轮, loss %f&quot;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epoch_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> epoch_loss <span class="token operator">&lt;</span> <span class="token number">0.01</span><span class="token punctuation">:</span>
        <span class="token keyword">break</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;训练后权重:&quot;</span><span class="token punctuation">,</span> w1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span> w3<span class="token punctuation">)</span>

Y1 <span class="token operator">=</span> <span class="token punctuation">[</span>func<span class="token punctuation">(</span>i<span class="token punctuation">,</span> w1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span> w3<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> X<span class="token punctuation">]</span>

plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">&quot;red&quot;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y1<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><pre><code>第0轮, loss 6.321148
第1轮, loss 0.193806
第2轮, loss 0.175068
第3轮, loss 0.113496
第4轮, loss 0.071707
第5轮, loss 0.045307
第6轮, loss 0.028787
第7轮, loss 0.018517
第8轮, loss 0.012185
第9轮, loss 0.008320
训练后权重: 1.0921032530910941 3.7601929231375175 3.9972206515728788
</code></pre><img width="534px" height="413px" src="data:image/png;base64,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"><h2 id="参考文献" tabindex="-1"><a class="header-anchor" href="#参考文献" aria-hidden="true">#</a> 参考文献</h2>`,10),is={href:"https://blog.csdn.net/weixin_44133119/article/details/123307291",target:"_blank",rel:"noopener noreferrer"},ms={href:"https://blog.csdn.net/SongGu1996/article/details/99056721",target:"_blank",rel:"noopener noreferrer"},rs={href:"https://zhuanlan.zhihu.com/p/409074600",target:"_blank",rel:"noopener noreferrer"};function us(ds,ks){const a=o("ExternalLinkIcon");return e(),c("div",null,[m,r,u,d,k,h,g,y,v,b,A,x,w,f,z,_,C,q,L,I,F,M,B,R,H,K,Q,W,P,S,T,N,V,Y,j,E,X,D,G,U,Z,J,O,$,ss,ns,as,ts,ls,ps,es,cs,os,s("p",null,[n("[1] "),s("a",is,[n("python学习 - copy模块的浅复制（copy）与深复制（deepcopy）"),t(a)])]),s("p",null,[n("[2] "),s("a",ms,[n("交叉熵损失函数（Cross Entropy Loss）"),t(a)])]),s("p",null,[n("[3] "),s("a",rs,[n("常见的损失函数(loss function)汇总"),t(a)])])])}const gs=p(i,[["render",us],["__file","week2 深度学习常用组件.html.vue"]]);export{gs as default};
